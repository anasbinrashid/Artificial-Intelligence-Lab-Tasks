{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXGnAEeXtirP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess(path):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Keep relevant columns\n",
        "    df = df[['Pclass', 'Gender', 'Age', 'Fare', 'Embarked', 'Survived']]\n",
        "\n",
        "    # TODO: Drop rows with missing values\n",
        "    df = df.dropna()      # inplace = True means original dataframe changed, false by default\n",
        "\n",
        "    # TODO: Convert Age to AgeGroup (Child if < 16, else Adult)\n",
        "    df['AgeGroup'] = df['Age'].apply(lambda x: 'Child' if x < 16 else 'Adult')\n",
        "    df = df.drop('Age', axis=1)       # axis=1 means columns are to be dropped and not rows\n",
        "\n",
        "    # TODO: Encode categorical features ('Gender', 'Embarked', 'AgeGroup')\n",
        "    df = pd.get_dummies(df, columns=['Gender', 'Embarked', 'AgeGroup'])  # one hot encoding using get_dummies\n",
        "\n",
        "    # TODO: Prepare X and y\n",
        "    X = df.drop('Survived', axis=1)\n",
        "    y = df['Survived']\n",
        "\n",
        "    # Return train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n"
      ],
      "metadata": {
        "id": "jpfIx03zl8Ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(y):\n",
        "    counts = np.bincount(y)\n",
        "    ## np.bincount() is a NumPy function that counts the occurrences of each non-negative integer value in an array. It returns an array where the index represents the value and the element at that index represents its count in the input array.\n",
        "    probabilities = counts / len(y)\n",
        "    entropy = -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
        "    return entropy\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qF_5dKxnl8SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def information_gain(X_column, y, threshold):\n",
        "    parent_entropy = entropy(y) # class entropy\n",
        "    # conditional entropy\n",
        "    y_left = y[X_column < threshold]\n",
        "    y_right = y[X_column >= threshold]\n",
        "    if len(y_left) == 0 or len(y_right) == 0:\n",
        "        return 0\n",
        "    prob_left = len(y_left) / len(y)\n",
        "    prob_right = len(y_right) / len(y)\n",
        "    child_entropy = prob_left * entropy(y_left) + prob_right * entropy(y_right)\n",
        "    ig = parent_entropy - child_entropy\n",
        "    return ig\n"
      ],
      "metadata": {
        "id": "bXNsYifNl8V2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def best_split(X, y):\n",
        "    best_split = {}\n",
        "    best_info_gain = -1\n",
        "    for feature in X.columns:\n",
        "        X_column = X[feature]\n",
        "        thresholds = np.unique(X_column)\n",
        "        for threshold in thresholds:\n",
        "            info_gain = information_gain(X_column, y, threshold)\n",
        "            if info_gain > best_info_gain:\n",
        "                best_split = {\n",
        "                    'feature': feature,\n",
        "                    'threshold': threshold,\n",
        "                    'info_gain': info_gain\n",
        "                }\n",
        "                best_info_gain = info_gain\n",
        "    return best_split\n"
      ],
      "metadata": {
        "id": "0vRF-AhooPd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value"
      ],
      "metadata": {
        "id": "Y8xl5Bz9oPfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_tree(X, y, depth=0, max_depth=5):\n",
        "    if depth == max_depth:\n",
        "        most_common_label = Counter(y).most_common(1)[0][0]\n",
        "        return Node(value=most_common_label)\n",
        "    else :\n",
        "        bestsplit = best_split(X, y)\n",
        "        if bestsplit['info_gain'] <= 0:\n",
        "            most_common_label = Counter(y).most_common(1)[0][0]\n",
        "            return Node(value=most_common_label)\n",
        "        else:\n",
        "            left_indices = X[bestsplit['feature']] < bestsplit['threshold']\n",
        "            right_indices = ~left_indices\n",
        "            left_subtree = build_tree(X[left_indices], y[left_indices], depth + 1, max_depth)\n",
        "            right_subtree = build_tree(X[right_indices], y[right_indices], depth + 1, max_depth)\n",
        "            return Node(bestsplit['feature'], bestsplit['threshold'], left_subtree, right_subtree)\n"
      ],
      "metadata": {
        "id": "wBceAYEAoPi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_one(x, node):\n",
        "    if node.value is not None:\n",
        "        return node.value\n",
        "    if x[node.feature] < node.threshold:\n",
        "        return predict_one(x, node.left)\n",
        "    else:\n",
        "        return predict_one(x, node.right)\n"
      ],
      "metadata": {
        "id": "e-kn8RQloPkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, tree):\n",
        "    y_pred = [predict_one(x, tree) for x in X.to_dict(orient='records')]\n",
        "    return y_pred\n"
      ],
      "metadata": {
        "id": "N9MvK0o7oZCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    X_train, X_test, y_train, y_test = load_and_preprocess(\"/titanic.csv\")\n",
        "\n",
        "    tree = build_tree(X_train, y_train, max_depth=5)\n",
        "    y_pred = predict(X_test, tree)\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "_d9q5ioBoPo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f4d537d-c1bb-4086-b0b8-cec0ddc7607a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7972027972027972\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.88      0.83        80\n",
            "           1       0.81      0.70      0.75        63\n",
            "\n",
            "    accuracy                           0.80       143\n",
            "   macro avg       0.80      0.79      0.79       143\n",
            "weighted avg       0.80      0.80      0.79       143\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n5oR3GE3pCcZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}